{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr6x1g4iKvuY4pTYT6hBPS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkb1902/Books/blob/main/Untitled50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "30Tmd6zefcf2"
      },
      "outputs": [],
      "source": [
        "#tweet sentiment analysis\n",
        "#step 1 import\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we get the datasets train test and sample_submission session storage\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test (1).csv')\n",
        "sample_submission = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "print(train.head())\n",
        "print(test.head())\n",
        "print(sample_submission.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pms9c7Cfimtd",
        "outputId": "23b71967-b283-461e-fcd0-e742c2a032a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       textID                                               text  \\\n",
            "0  cb774db0d1                I`d have responded, if I were going   \n",
            "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
            "2  088c60f138                          my boss is bullying me...   \n",
            "3  9642c003ef                     what interview! leave me alone   \n",
            "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
            "\n",
            "                         selected_text sentiment  \n",
            "0  I`d have responded, if I were going   neutral  \n",
            "1                             Sooo SAD  negative  \n",
            "2                          bullying me  negative  \n",
            "3                       leave me alone  negative  \n",
            "4                        Sons of ****,  negative  \n",
            "       textID                                               text sentiment\n",
            "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
            "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
            "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
            "3  01082688c6                                        happy bday!  positive\n",
            "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive\n",
            "       textID  selected_text\n",
            "0  f87dea47db            NaN\n",
            "1  96d74cb729            NaN\n",
            "2  eee518ae67            NaN\n",
            "3  01082688c6            NaN\n",
            "4  33987a8ee5            NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train['sentiment'].value_counts())\n",
        "print(train.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7E6mw3BjRTF",
        "outputId": "4d1c4d40-be45-44b1-bc61-f9878156ad5b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "neutral     11118\n",
            "positive     8582\n",
            "negative     7781\n",
            "Name: count, dtype: int64\n",
            "Index(['textID', 'text', 'selected_text', 'sentiment'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train['selected_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlRkY4Xk2M4a",
        "outputId": "f482f0b3-2151-4ab1-a7e9-bce15d5a2ba7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                      I`d have responded, if I were going\n",
            "1                                                 Sooo SAD\n",
            "2                                              bullying me\n",
            "3                                           leave me alone\n",
            "4                                            Sons of ****,\n",
            "                               ...                        \n",
            "27476                                               d lost\n",
            "27477                                        , don`t force\n",
            "27478                            Yay good for both of you.\n",
            "27479                           But it was worth it  ****.\n",
            "27480    All this flirting going on - The ATG smiles. Y...\n",
            "Name: selected_text, Length: 27481, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows us that we have 4 columns in our dataset which are text id and text and the selected text and the actual sentiment which shall be our resulgt class\n"
      ],
      "metadata": {
        "id": "fnkm-dcKXGuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train['text'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7fs6cpJXlFz",
        "outputId": "cddfb7a6-f4d7-44ff-bbbf-265eae93973f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                  I`d have responded, if I were going\n",
            "1        Sooo SAD I will miss you here in San Diego!!!\n",
            "2                            my boss is bullying me...\n",
            "3                       what interview! leave me alone\n",
            "4     Sons of ****, why couldn`t they put them on t...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so this data happens to contain  a number of special characters and these can pollute the model also we need to remove the spaces that are unneccesary from our data.we should also remove the urls and shift to lowercase for consistency."
      ],
      "metadata": {
        "id": "CQg5APUv2jEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#creating a function to clean the data by removing the urls,special characters and extra spaces\n",
        "import re\n",
        "def cleanData(text):\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text,flags=re.MULTILINE)#this is removing the url components\n",
        "    text = re.sub(r'<.*?>!`', '', text)#removing html\n",
        "    text = re.sub(r'\\s+', ' ', text)#removing extra spaces\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)#removing special characters\n",
        "    text = ' '.join(text.split())#recombining the data\n",
        "    text = text.lower()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "_6mO0ahC230w"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hSGGhj866g6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#our function need all the values to be text so we need to check for any missing values and stuff\n",
        "print(train['text'].isnull().sum())\n",
        "print(train['selected_text'].isnull().sum())\n",
        "print(test['text'].isnull().sum())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8p7wrKD4m1x",
        "outputId": "09d313a5-15d8-47d0-ef1f-75f43eabfd8b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this tells of the 3 dbs 2 of them each have 1 value missing and since the number is so minor we can just remove it"
      ],
      "metadata": {
        "id": "4RmVRrs_BzFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#removing the rows with the missing values\n",
        "train = train.dropna()\n"
      ],
      "metadata": {
        "id": "Y_jucE6M8ODg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train['text'].isnull().sum())\n",
        "print(train['selected_text'].isnull().sum())\n",
        "print(test['text'].isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oCfAL5-CQjm",
        "outputId": "983d283a-4028-4007-a221-2b6da30d46dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaning the data\n",
        "train['text'] = train['text'].apply(cleanData)\n",
        "train['selected_text'] = train['selected_text'].apply(cleanData)\n",
        "test['text'] = test['text'].apply(cleanData)\n"
      ],
      "metadata": {
        "id": "dgEh-nqFCWp4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train['text'].head())\n",
        "print(train['selected_text'].head())\n",
        "print(test['text'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIwhYX_jCgRP",
        "outputId": "27388981-5420-4f2f-b6c1-a0e408d66b32"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                    id have responded if i were going\n",
            "1           sooo sad i will miss you here in san diego\n",
            "2                               my boss is bullying me\n",
            "3                        what interview leave me alone\n",
            "4    sons of why couldnt they put them on the relea...\n",
            "Name: text, dtype: object\n",
            "0    id have responded if i were going\n",
            "1                             sooo sad\n",
            "2                          bullying me\n",
            "3                       leave me alone\n",
            "4                              sons of\n",
            "Name: selected_text, dtype: object\n",
            "0                              last session of the day\n",
            "1    shanghai is also really exciting precisely sky...\n",
            "2    recession hit veronique branquinho she has to ...\n",
            "3                                           happy bday\n",
            "4                                            i like it\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WPOkcdyChnQ",
        "outputId": "d1df4bd0-e8e1-402c-d6f2-7f83821ac196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                    id have responded if i were going\n",
            "1           sooo sad i will miss you here in san diego\n",
            "2                               my boss is bullying me\n",
            "3                        what interview leave me alone\n",
            "4    sons of why couldnt they put them on the relea...\n",
            "Name: text, dtype: object\n",
            "0    id have responded if i were going\n",
            "1                             sooo sad\n",
            "2                          bullying me\n",
            "3                       leave me alone\n",
            "4                              sons of\n",
            "Name: selected_text, dtype: object\n",
            "0                              last session of the day\n",
            "1    shanghai is also really exciting precisely sky...\n",
            "2    recession hit veronique branquinho she has to ...\n",
            "3                                           happy bday\n",
            "4                                            i like it\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#after we remove all the unwanted material from our model we now make an effort to tokenize our data\n",
        "#we shall perfom word tokenization to split the data into the separate words\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "train['tokenized_text'] = train['text'].apply(word_tokenize)\n",
        "train['tokenized_selected_text'] = train['selected_text'].apply(word_tokenize)\n",
        "test['tokenized_text'] = test['text'].apply(word_tokenize)\n",
        "\n",
        "print(train['tokenized_text'].head())\n",
        "print(train['tokenized_selected_text'].head())\n",
        "print(test['tokenized_text'].head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh3_lsCcNyhD",
        "outputId": "85904b57-9d84-4472-e094-4c91dab9f4d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0            [id, have, responded, if, i, were, going]\n",
            "1    [sooo, sad, i, will, miss, you, here, in, san,...\n",
            "2                         [my, boss, is, bullying, me]\n",
            "3                  [what, interview, leave, me, alone]\n",
            "4    [sons, of, why, couldnt, they, put, them, on, ...\n",
            "Name: tokenized_text, dtype: object\n",
            "0    [id, have, responded, if, i, were, going]\n",
            "1                                  [sooo, sad]\n",
            "2                               [bullying, me]\n",
            "3                           [leave, me, alone]\n",
            "4                                   [sons, of]\n",
            "Name: tokenized_selected_text, dtype: object\n",
            "0                        [last, session, of, the, day]\n",
            "1    [shanghai, is, also, really, exciting, precise...\n",
            "2    [recession, hit, veronique, branquinho, she, h...\n",
            "3                                        [happy, bday]\n",
            "4                                        [i, like, it]\n",
            "Name: tokenized_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#after tokenization we perform label encoding\n",
        "#it is used to convert categorical data into numerical format\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "train['sentiment'] = le.fit_transform(train['sentiment'])\n",
        "print(train['sentiment'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ma3bdVBHcug",
        "outputId": "364d2165-6400-47c7-fd22-00a89a49362f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    1\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: sentiment, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we procced to create our model\n",
        "model = ten"
      ],
      "metadata": {
        "id": "XblHqR3ZH7yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "IgWuPzbDH8BO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}